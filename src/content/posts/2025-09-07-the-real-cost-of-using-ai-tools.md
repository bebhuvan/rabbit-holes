---
title: The real cost of using AI tools
date: 2025-09-08
type: musings
published: false
draft: true
featured: false
---
> Role of the AI  
>   
> To summarize, we can say that the role played by the AI was essentially that of an executor, responding to our successive prompts. Without us, it would have made a damaging error in the Gaussian case, and it would not have provided the most interesting result in the Poisson case, overlooking an essential property of covariance, which was in fact easily deducible from the results contained in the document we had provided.
> 
> _5 Some personal reflections_  
>   
> Overall, the experience of doing mathematics with GPT-5 was mixed. It felt very similar to working with a junior assistant at the beginning of a new project: exploring directions, formulating hypotheses, searching for counterexamples, and progressively adjusting statements. The AI showed a genuine ability to follow guided reasoning, to recognize its mistakes when pointed out, to propose new research directions, and to never take on the task. However, this only seems to support incremental research, that is, producing new results that do not require genuinely new ideas but rather the ability to combine ideas coming from different sources. At first glance, this might appear useful for an exploratory phase, helping us save time. In practice, however, it was quite the opposite: we had to carefully verify everything produced by the AI and constantly guide it so that it could correct its mistakes.  
>   
> The main risk we see with this technology, in its current state, is that it will almost certainly lead to a proliferation of incremental results produced with AI. This could saturate the scientific landscape with technically correct but only moderately interesting contributions, making it harder for truly original work to stand out. The situation is reminiscent of other cultural domains already transformed by mass generative technologies: a flood of technically competent but uninspired outputs that dilutes attention and raises the noise level.  
>   
> We also foresee a second, more specific negative effect, concerning PhD students. Traditionally, when PhD students begin their dissertation, they are given a problem that is accessible but rich enough to help them become familiar with the tools, develop intuition, and learn to recognize what works and what does not. They typically read several papers, explore how a theory could be adapted, make mistakes, and eventually find their own path. This process, with all its difficulties, is part of what makes them independent researchers. If students rely too heavily on AI systems that can immediately generate technically correct but shallow arguments, they may lose essential opportunities to develop these fundamental skills. The danger is not only a loss of originality, but also a weakening of the very process of becoming a mathematician.  
>   
> In conclusion, we are still far from sharing the unreserved enthusiasm sparked by Bubeckâ€™s post. Nevertheless, this development deserves close monitoring. The improvement over GPT-3.5/4 has been significant and achieved in a remarkably short time, which suggests that further advances are to be expected. Whether such progress could one day substantially displace the role of mathematicians remains an open question that only the future will tell.