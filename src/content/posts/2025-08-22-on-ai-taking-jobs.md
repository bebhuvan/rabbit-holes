---
title: On AI taking jobs
date: 2025-08-22
type: link-dumps
tags:
  - AI
published: true
draft: false
featured: false
---
Making sense of reality as it unfolds is always hard because of the variance in outcomes. With Artificial Intelligence, that difficulty compounds massively. Both the narrative variance and the actual variance of potential AI outcomes are so vast that having strong opinions isn’t really a luxury one can afford. If one’s uncertainty band about what AI can do doesn’t range from 0 to 100, they are exquisitely buggered.

So my default frame for thinking about AI has been to be ok with the uncertainty and to avoid forming strong, dogmatic views.

In line with book [_Framers_](https://www.amazon.in/Framers-Human-Advantage-Technology-Turmoil/dp/0593182596?dplnkId=aa036ba9-934b-4456-9322-ac32a2cb88a5&nodl=1), I’ve been looking for frames—mental models—to make sense of the world that AI seems poised to reshape. And in doing this, I try look everywhere for evidence, ideas, data, and opinion: from articles about McKinsey losing its [sheen](https://www.economist.com/leaders/2025/08/07/mckinsey-and-its-peers-need-a-new-strategy-and-some-humility), to spiking admissions into [trade academies](https://www.nbcnews.com/business/business-news/ai-which-jobs-are-skilled-trades-protected-what-to-know-rcna223249) for electricians and plumbers, to reduced guidance and flat results from IT companies, to surveys, and more. Of course, I also regulary use these tools to make sense of them.

I try obsessively try to keep track of what’s happening with AI progress, because this is a general-purpose technology. At this point, I think there’s a reasonably high probability that AI will reshape large parts of the economy and, by extension, society—and therefore change the way we live our lives.

I can always change my mind, but for now, that’s my Bayesian prior.

I reading about AI, I came across two articles with two useful frames on AI and how they’ll affect jobs.

From Brian Merchant’s [Blood in the Machine newsletter](https://www.bloodinthemachine.com/p/ai-killed-my-job-translators):

> It’s of course unclear what the future holds, but there’s a growing sense that the AI phenomenon is more bubble than boom. As such, rather than viewing the enterprise AI frenzy on Silicon Valley’s terms, as an inevitable jobs apocalypse, we have an opportunity to view it on material terms, and examine how it’s actually playing out on the ground. On those terms, we see managers, executives, and corporations using rebranded automation software to increase volume and cut labor costs, starting with the most precarious workers. After all, an AI system does not have to be super-powerful for management to use it to degrade, deskill, and kill jobs. This, it seems, is what translators, interpreters, and localizers are experiencing, right now, on the front lines of the real AI jobs crisis. And these are their stories.

From [another edition](https://www.bloodinthemachine.com/p/the-ai-jobs-apocalypse-is-for-the):

> But of course there is no AI jobs \_apocalypse—\_an apocalypse is catastrophic, terminal, predetermined—but there _are_ bosses with great new incentives/justifications for firing people, for cutting costs, for speeding up work. There is, to split hairs for a minute, [a real AI jobs _crisis_](https://www.bloodinthemachine.com/p/the-ai-jobs-crisis-is-here-now), but that crisis is born of executives like Peng, CEOs like Duolingo’s Louis von Ahn and Klarna’s Sebastian Siemiatkowski all buying what Amodei (and Sam Altman, and the rest of the new AI enthusetariat) is selling. Amodei and the rest are pushing not just automation tools, but an entire new permission structure for enacting that job automation—and a framework that presents the whole phenomenon as outside their control.

This is an interesting frame. We’re not yet sure whether AI is taking jobs are not, but what it is doing is give managers and companies an opportunity to use the threat to fire people and push wages lower.

[From Lawrence Lundy-Brian](https://stateofthefuture.substack.com/p/unbundling-the-job?utm_medium=ios):

> True step-change productivity will require a reconfiguration of the workflow itself — where tasks are not just sped up, but redefined or eliminated. That’s when unbundling accelerates. The classic example is how early factories initially just replaced steam engines with electric motors but kept the same centralised power distribution system, long belts and shafts running throughout the building from a single power source. This provided some benefits but didn't fundamentally change how work was organized. The real transformation came when factories redesigned around electric motors' unique advantage: you could put individual motors at each workstation. This enabled the assembly line, where work flowed in sequence rather than being centralised around one power source. It also allowed for much more flexible factory layouts since you weren't constrained by the need to distribute mechanical power from a central point.
> 
> The parallel to AI is that we're currently in the "electric motor replacing steam engine" phase, where AI tools are being dropped into existing workflows to speed up specific tasks. Use AI to make slides faster, or automate emails, or vibecode. But the real quiz is: why are we even making slides or sending emails or coding? What is the job to be done? Imagine a world in which, we don’t actually make slides at all? Maybe we make a video instead? Or decision-makers just get their agent to make a video by pulling real-time sales data instead of asking “juniors” or consultants to do it?

I like this frame. We’ll truly know the impact of AI when companies reorganize their workflows around AI as oposed workers integrating AI in their workflows.

Also see [these links](https://www.rabbitholes.garden/posts/2025-08-15-is-the-twilight-of-the-humans-a-few-ai-links).